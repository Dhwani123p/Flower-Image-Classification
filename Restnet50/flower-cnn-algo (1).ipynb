{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2431805,"sourceType":"datasetVersion","datasetId":8782},{"sourceId":11493311,"sourceType":"datasetVersion","datasetId":7204815},{"sourceId":11493483,"sourceType":"datasetVersion","datasetId":7204947}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install necessary packages (if needed)\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\n\n# Imports\nimport numpy as np\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nfrom keras.utils import to_categorical\nfrom keras.applications import ResNet50\nfrom keras.models import Model\nfrom keras.layers import Dense, Flatten, Dropout\nfrom keras.optimizers import Adam\n#from keras.preprocessing.image import ImageDataGenerator\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T02:28:16.201853Z","iopub.execute_input":"2025-04-21T02:28:16.202376Z","iopub.status.idle":"2025-04-21T02:28:16.208481Z","shell.execute_reply.started":"2025-04-21T02:28:16.202349Z","shell.execute_reply":"2025-04-21T02:28:16.207350Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X=[]\nZ=[]\nIMG_SIZE=150\nFLOWER_DAISY_DIR='../input/flowers-recognition/flowers/daisy'\nFLOWER_SUNFLOWER_DIR='../input/flowers-recognition/flowers/sunflower'\nFLOWER_TULIP_DIR='../input/flowers-recognition/flowers/tulip'\nFLOWER_DANDI_DIR='../input/flowers-recognition/flowers/dandelion'\nFLOWER_ROSE_DIR='../input/flowers-recognition/flowers/rose'\nprint(\"Done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T02:28:22.835642Z","iopub.execute_input":"2025-04-21T02:28:22.835941Z","iopub.status.idle":"2025-04-21T02:28:22.851844Z","shell.execute_reply.started":"2025-04-21T02:28:22.835922Z","shell.execute_reply":"2025-04-21T02:28:22.850867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMG_SIZE = 150\nX = []\nZ = []\nflower_classes = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n\nfor flower in flower_classes:\n    path = f'../input/flowers-recognition/flowers/{flower}'\n    for img_name in tqdm(os.listdir(path), desc=f'Loading {flower}'):\n        img_path = os.path.join(path, img_name)\n        try:\n            img = cv2.imread(img_path)\n            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n            X.append(img)\n            Z.append(flower.capitalize())\n        except:\n            pass\n\n# Normalize and encode labels\nX = np.array(X) / 255.0\nle = LabelEncoder()\nY = to_categorical(le.fit_transform(Z), num_classes=5)\n\n# Split data\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T02:28:27.854164Z","iopub.execute_input":"2025-04-21T02:28:27.854508Z","iopub.status.idle":"2025-04-21T02:28:43.102207Z","shell.execute_reply.started":"2025-04-21T02:28:27.854483Z","shell.execute_reply":"2025-04-21T02:28:43.100883Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_model = ResNet50(weights='/kaggle/input/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nx = base_model.output\nx = Flatten()(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\noutput = Dense(5, activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input, outputs=output)\n\nmodel.compile(optimizer=Adam(learning_rate=0.0001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T02:38:51.710089Z","iopub.execute_input":"2025-04-21T02:38:51.710747Z","iopub.status.idle":"2025-04-21T02:38:54.420052Z","shell.execute_reply.started":"2025-04-21T02:38:51.710715Z","shell.execute_reply":"2025-04-21T02:38:54.419245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True\n)\n\ndatagen.fit(x_train)\n\nhistory = model.fit(\n    datagen.flow(x_train, y_train, batch_size=64),\n    epochs=10,\n    validation_data=(x_test, y_test),\n    steps_per_epoch=len(x_train) // 64\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T02:39:52.035948Z","iopub.execute_input":"2025-04-21T02:39:52.036305Z","iopub.status.idle":"2025-04-21T03:03:23.218437Z","shell.execute_reply.started":"2025-04-21T02:39:52.036281Z","shell.execute_reply":"2025-04-21T03:03:23.217367Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Accuracy plot\nplt.plot(history.history['accuracy'], label='Train')\nplt.plot(history.history['val_accuracy'], label='Validation')\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\n# Loss plot\nplt.plot(history.history['loss'], label='Train')\nplt.plot(history.history['val_loss'], label='Validation')\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T03:10:00.233179Z","iopub.execute_input":"2025-04-21T03:10:00.234177Z","iopub.status.idle":"2025-04-21T03:10:00.645458Z","shell.execute_reply.started":"2025-04-21T03:10:00.234148Z","shell.execute_reply":"2025-04-21T03:10:00.644512Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = model.predict(x_test)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true = np.argmax(y_test, axis=1)\n\n# Confusion Matrix\ncm = confusion_matrix(y_true, y_pred_classes)\nplt.figure(figsize=(8,6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Oranges',\n            xticklabels=le.classes_,\n            yticklabels=le.classes_)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\n# Classification Report\nprint(\"Classification Report:\\n\")\nprint(classification_report(y_true, y_pred_classes, target_names=le.classes_))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T03:10:26.220077Z","iopub.execute_input":"2025-04-21T03:10:26.220425Z","iopub.status.idle":"2025-04-21T03:11:17.763260Z","shell.execute_reply.started":"2025-04-21T03:10:26.220400Z","shell.execute_reply":"2025-04-21T03:11:17.762335Z"}},"outputs":[],"execution_count":null}]}